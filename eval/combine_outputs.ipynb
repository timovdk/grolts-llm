{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62a6b0dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "CASESTUDIES = [\"wellbeing\", \"achievement\", \"delinquency\", \"ptsd\"]\n",
    "MODELS = {\n",
    "    \"gpt-5-mini\": \"gpt-5-mini\",\n",
    "    \"phi-4\": \"Phi-4\",\n",
    "    \"microsoft_phi-4\": \"Phi-4\",\n",
    "    \"Qwen_Qwen3-30B\": \"Qwen-3-30B\",\n",
    "    \"Qwen_Qwen3-30B-A3B-Instruct-2507\": \"Qwen-3-30B\",\n",
    "    \"Qwen_Qwen3-Next-80B-A3B-Instruct\": \"Qwen-Next-80B\",\n",
    "    \"meta-llama_Llama-3.3-70B-Instruct\": \"Llama-3.3-70B\",\n",
    "    \"mistralai_Magistral-Small-2509\": \"Magistral-Small\",\n",
    "}\n",
    "QUESTION_SET = [0, 4]\n",
    "HUMAN_FILES = {\n",
    "    \"wellbeing\": \"./human_labels/wellbeing.csv\",\n",
    "    \"achievement\": \"./human_labels/achievement.csv\",\n",
    "    \"delinquency\": \"./human_labels/delinquency.csv\",\n",
    "    \"ptsd\": \"./human_labels/ptsd.csv\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4bddd7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = glob.glob(\"./outputs/*.csv\")\n",
    "# Container for all dataframes\n",
    "dfs = []\n",
    "\n",
    "for file in files:\n",
    "    df = pd.read_csv(file)\n",
    "    filename = os.path.basename(file).replace(\".csv\", \"\")\n",
    "\n",
    "    # Extract question_set (last number in filename)\n",
    "    question_set = int(filename.split(\"_\")[-1])\n",
    "\n",
    "    # Extract casestudy (second-to-last element)\n",
    "    casestudy = next((cs for cs in CASESTUDIES if cs in filename.lower()), \"unknown\")\n",
    "\n",
    "    # Extract model by matching keys in MODELS\n",
    "    model_key = None\n",
    "    for key in MODELS.keys():\n",
    "        if key.lower() in filename.lower():\n",
    "            model_key = key\n",
    "            break\n",
    "    model = MODELS.get(model_key, \"unknown\")\n",
    "\n",
    "    # Add as new columns\n",
    "    df[\"model\"] = model\n",
    "    df[\"casestudy\"] = casestudy\n",
    "    df[\"question_set\"] = question_set\n",
    "\n",
    "    dfs.append(df)\n",
    "\n",
    "\n",
    "human_dfs = []\n",
    "for casestudy, path in HUMAN_FILES.items():\n",
    "    df = pd.read_csv(path, sep=\";\")\n",
    "\n",
    "    # Melt columns 0â€“18 into long format\n",
    "    df_long = df.melt(id_vars=[\"paper_id\"], var_name=\"question_id\", value_name=\"answer\")\n",
    "\n",
    "    # Add metadata columns\n",
    "    df_long[\"casestudy\"] = casestudy\n",
    "    df_long[\"model\"] = \"human\"\n",
    "    df_long[\"question_set\"] = 0 if casestudy == \"ptsd\" else 3\n",
    "    df_long[\"reasoning\"] = \"-\"\n",
    "    df_long[\"evidence\"] = \"-\"\n",
    "\n",
    "    # Ensure correct column order and types\n",
    "    df_long[\"question_id\"] = df_long[\"question_id\"].astype(int)\n",
    "    df_long = df_long[\n",
    "        [\n",
    "            \"casestudy\",\n",
    "            \"model\",\n",
    "            \"question_set\",\n",
    "            \"paper_id\",\n",
    "            \"question_id\",\n",
    "            \"reasoning\",\n",
    "            \"evidence\",\n",
    "            \"answer\",\n",
    "        ]\n",
    "    ]\n",
    "\n",
    "    human_dfs.append(df_long)\n",
    "\n",
    "# Combine all human annotations\n",
    "human_combined = pd.concat(human_dfs, ignore_index=True)\n",
    "\n",
    "# Combine all\n",
    "combined_df = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "# Reorder columns\n",
    "column_order = [\n",
    "    \"casestudy\",\n",
    "    \"model\",\n",
    "    \"question_set\",\n",
    "    \"paper_id\",\n",
    "    \"question_id\",\n",
    "    \"reasoning\",\n",
    "    \"evidence\",\n",
    "    \"answer\",\n",
    "]\n",
    "combined_df = combined_df[column_order]\n",
    "\n",
    "# Merge with your existing model results\n",
    "final_df = pd.concat([combined_df, human_combined], ignore_index=True)\n",
    "\n",
    "# Optional: save to Excel\n",
    "final_df.to_excel(\"./combined.xlsx\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "grolts",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
